{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, h5py\n",
    "\n",
    "datafile = h5py.File('SCNeuronModelCompetition.mat')\n",
    "movie = datafile.get('trainingmovie_norm') # movie for training\n",
    "frhist = datafile.get('FRhist_tr') # firing rate histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import TimeDistributed, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 150, 65)           798785    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 150, 65)           4290      \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 150, 54)           3564      \n",
      "=================================================================\n",
      "Total params: 806,639\n",
      "Trainable params: 806,639\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/40\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.7240 - val_loss: 0.6505\n",
      "Epoch 2/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.6122 - val_loss: 0.5614\n",
      "Epoch 3/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.5321 - val_loss: 0.4943\n",
      "Epoch 4/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.4728 - val_loss: 0.4456\n",
      "Epoch 5/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4302 - val_loss: 0.4115\n",
      "Epoch 6/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4012 - val_loss: 0.3888\n",
      "Epoch 7/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3819 - val_loss: 0.3739\n",
      "Epoch 8/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3693 - val_loss: 0.3641\n",
      "Epoch 9/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3611 - val_loss: 0.3576\n",
      "Epoch 10/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3556 - val_loss: 0.3534\n",
      "Epoch 11/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3520 - val_loss: 0.3506\n",
      "Epoch 12/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3496 - val_loss: 0.3488\n",
      "Epoch 13/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3479 - val_loss: 0.3475\n",
      "Epoch 14/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3466 - val_loss: 0.3463\n",
      "Epoch 15/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3457 - val_loss: 0.3455\n",
      "Epoch 16/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3450 - val_loss: 0.3449\n",
      "Epoch 17/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3444 - val_loss: 0.3445\n",
      "Epoch 18/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3440 - val_loss: 0.3441\n",
      "Epoch 19/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3437 - val_loss: 0.3439\n",
      "Epoch 20/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3434 - val_loss: 0.3437\n",
      "Epoch 21/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3432 - val_loss: 0.3434\n",
      "Epoch 22/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3430 - val_loss: 0.3433\n",
      "Epoch 23/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3429 - val_loss: 0.3434\n",
      "Epoch 24/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3427 - val_loss: 0.3433\n",
      "Epoch 25/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3425 - val_loss: 0.3431\n",
      "Epoch 26/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3425 - val_loss: 0.3430\n",
      "Epoch 27/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3424 - val_loss: 0.3428\n",
      "Epoch 28/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3422 - val_loss: 0.3428\n",
      "Epoch 29/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3422 - val_loss: 0.3428\n",
      "Epoch 30/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3421 - val_loss: 0.3428\n",
      "Epoch 31/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3420 - val_loss: 0.3427\n",
      "Epoch 32/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3419 - val_loss: 0.3426\n",
      "Epoch 33/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3418 - val_loss: 0.3425\n",
      "Epoch 34/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3418 - val_loss: 0.3424\n",
      "Epoch 35/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3417 - val_loss: 0.3425\n",
      "Epoch 36/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3417 - val_loss: 0.3426\n",
      "Epoch 37/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3416 - val_loss: 0.3426\n",
      "Epoch 38/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3415 - val_loss: 0.3425\n",
      "Epoch 39/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3414 - val_loss: 0.3424\n",
      "Epoch 40/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3413 - val_loss: 0.3424\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_4 (TimeDist (None, 150, 75)           921675    \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 150, 75)           5700      \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 150, 54)           4104      \n",
      "=================================================================\n",
      "Total params: 931,479\n",
      "Trainable params: 931,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.6811 - val_loss: 0.6000\n",
      "Epoch 2/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.5612 - val_loss: 0.5076\n",
      "Epoch 3/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4797 - val_loss: 0.4428\n",
      "Epoch 4/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.4243 - val_loss: 0.4014\n",
      "Epoch 5/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3904 - val_loss: 0.3772\n",
      "Epoch 6/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3710 - val_loss: 0.3636\n",
      "Epoch 7/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3603 - val_loss: 0.3560\n",
      "Epoch 8/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3541 - val_loss: 0.3515\n",
      "Epoch 9/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3504 - val_loss: 0.3487\n",
      "Epoch 10/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3479 - val_loss: 0.3470\n",
      "Epoch 11/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3463 - val_loss: 0.3458\n",
      "Epoch 12/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3452 - val_loss: 0.3451\n",
      "Epoch 13/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3444 - val_loss: 0.3444\n",
      "Epoch 14/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3439 - val_loss: 0.3441\n",
      "Epoch 15/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3433 - val_loss: 0.3438\n",
      "Epoch 16/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3430 - val_loss: 0.3435\n",
      "Epoch 17/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3427 - val_loss: 0.3432\n",
      "Epoch 18/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3424 - val_loss: 0.3431\n",
      "Epoch 19/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3422 - val_loss: 0.3432\n",
      "Epoch 20/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3421 - val_loss: 0.3431\n",
      "Epoch 21/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3418 - val_loss: 0.3429\n",
      "Epoch 22/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3416 - val_loss: 0.3428\n",
      "Epoch 23/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3415 - val_loss: 0.3428\n",
      "Epoch 24/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3413 - val_loss: 0.3427\n",
      "Epoch 25/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3412 - val_loss: 0.3426\n",
      "Epoch 26/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3410 - val_loss: 0.3426\n",
      "Epoch 27/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3409 - val_loss: 0.3426\n",
      "Epoch 28/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3407 - val_loss: 0.3427\n",
      "Epoch 29/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3406 - val_loss: 0.3427\n",
      "Epoch 30/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3404 - val_loss: 0.3425\n",
      "Epoch 31/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3402 - val_loss: 0.3424\n",
      "Epoch 32/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3400 - val_loss: 0.3424\n",
      "Epoch 33/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3398 - val_loss: 0.3424\n",
      "Epoch 34/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3396 - val_loss: 0.3424\n",
      "Epoch 35/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3395 - val_loss: 0.3424\n",
      "Epoch 36/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3392 - val_loss: 0.3423\n",
      "Epoch 37/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3392 - val_loss: 0.3424\n",
      "Epoch 38/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3390 - val_loss: 0.3424\n",
      "Epoch 39/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3388 - val_loss: 0.3423\n",
      "Epoch 40/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3386 - val_loss: 0.3424\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_7 (TimeDist (None, 150, 85)           1044565   \n",
      "_________________________________________________________________\n",
      "time_distributed_8 (TimeDist (None, 150, 85)           7310      \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, 150, 54)           4644      \n",
      "=================================================================\n",
      "Total params: 1,056,519\n",
      "Trainable params: 1,056,519\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.7597 - val_loss: 0.6623\n",
      "Epoch 2/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.6184 - val_loss: 0.5556\n",
      "Epoch 3/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.5240 - val_loss: 0.4793\n",
      "Epoch 4/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.4583 - val_loss: 0.4276\n",
      "Epoch 5/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4146 - val_loss: 0.3947\n",
      "Epoch 6/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3870 - val_loss: 0.3749\n",
      "Epoch 7/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3706 - val_loss: 0.3634\n",
      "Epoch 8/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3607 - val_loss: 0.3565\n",
      "Epoch 9/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3547 - val_loss: 0.3521\n",
      "Epoch 10/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3509 - val_loss: 0.3494\n",
      "Epoch 11/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3486 - val_loss: 0.3476\n",
      "Epoch 12/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3470 - val_loss: 0.3465\n",
      "Epoch 13/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3459 - val_loss: 0.3456\n",
      "Epoch 14/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3450 - val_loss: 0.3450\n",
      "Epoch 15/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3445 - val_loss: 0.3445\n",
      "Epoch 16/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3440 - val_loss: 0.3440\n",
      "Epoch 17/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3437 - val_loss: 0.3438\n",
      "Epoch 18/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3435 - val_loss: 0.3437\n",
      "Epoch 19/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3432 - val_loss: 0.3435\n",
      "Epoch 20/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3430 - val_loss: 0.3433\n",
      "Epoch 21/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3428 - val_loss: 0.3431\n",
      "Epoch 22/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3427 - val_loss: 0.3430\n",
      "Epoch 23/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3425 - val_loss: 0.3429\n",
      "Epoch 24/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3424 - val_loss: 0.3429\n",
      "Epoch 25/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3423 - val_loss: 0.3428\n",
      "Epoch 26/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3422 - val_loss: 0.3429\n",
      "Epoch 27/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3421 - val_loss: 0.3428\n",
      "Epoch 28/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3420 - val_loss: 0.3427\n",
      "Epoch 29/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3419 - val_loss: 0.3426\n",
      "Epoch 30/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3418 - val_loss: 0.3427\n",
      "Epoch 31/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3417 - val_loss: 0.3426\n",
      "Epoch 32/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3416 - val_loss: 0.3423\n",
      "Epoch 33/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3414 - val_loss: 0.3425\n",
      "Epoch 34/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3413 - val_loss: 0.3425\n",
      "Epoch 35/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3411 - val_loss: 0.3425\n",
      "Epoch 36/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3410 - val_loss: 0.3423\n",
      "Epoch 37/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3408 - val_loss: 0.3423\n",
      "Epoch 38/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3407 - val_loss: 0.3422\n",
      "Epoch 39/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3406 - val_loss: 0.3423\n",
      "Epoch 40/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3405 - val_loss: 0.3424\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_10 (TimeDis (None, 150, 95)           1167455   \n",
      "_________________________________________________________________\n",
      "time_distributed_11 (TimeDis (None, 150, 95)           9120      \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 150, 54)           5184      \n",
      "=================================================================\n",
      "Total params: 1,181,759\n",
      "Trainable params: 1,181,759\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.6982 - val_loss: 0.5997\n",
      "Epoch 2/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.5563 - val_loss: 0.4943\n",
      "Epoch 3/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4660 - val_loss: 0.4260\n",
      "Epoch 4/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4091 - val_loss: 0.3857\n",
      "Epoch 5/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3770 - val_loss: 0.3645\n",
      "Epoch 6/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3601 - val_loss: 0.3543\n",
      "Epoch 7/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3523 - val_loss: 0.3494\n",
      "Epoch 8/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3481 - val_loss: 0.3469\n",
      "Epoch 9/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3460 - val_loss: 0.3456\n",
      "Epoch 10/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3447 - val_loss: 0.3448\n",
      "Epoch 11/40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3438 - val_loss: 0.3443\n",
      "Epoch 12/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3433 - val_loss: 0.3439\n",
      "Epoch 13/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3428 - val_loss: 0.3436\n",
      "Epoch 14/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3425 - val_loss: 0.3433\n",
      "Epoch 15/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3423 - val_loss: 0.3432\n",
      "Epoch 16/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3420 - val_loss: 0.3430\n",
      "Epoch 17/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3419 - val_loss: 0.3430\n",
      "Epoch 18/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3418 - val_loss: 0.3428\n",
      "Epoch 19/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3415 - val_loss: 0.3427\n",
      "Epoch 20/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3414 - val_loss: 0.3426\n",
      "Epoch 21/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3412 - val_loss: 0.3426\n",
      "Epoch 22/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3411 - val_loss: 0.3427\n",
      "Epoch 23/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3409 - val_loss: 0.3426\n",
      "Epoch 24/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3410 - val_loss: 0.3426\n",
      "Epoch 25/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3408 - val_loss: 0.3427\n",
      "Epoch 26/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3407 - val_loss: 0.3427\n",
      "Epoch 27/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3405 - val_loss: 0.3424\n",
      "Epoch 28/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3404 - val_loss: 0.3425\n",
      "Epoch 29/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3403 - val_loss: 0.3424\n",
      "Epoch 30/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3401 - val_loss: 0.3423\n",
      "Epoch 31/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3401 - val_loss: 0.3424\n",
      "Epoch 32/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3398 - val_loss: 0.3425\n",
      "Epoch 33/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3397 - val_loss: 0.3424\n",
      "Epoch 34/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3396 - val_loss: 0.3424\n",
      "Epoch 35/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3395 - val_loss: 0.3424\n",
      "Epoch 36/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3394 - val_loss: 0.3426\n",
      "Epoch 37/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3392 - val_loss: 0.3424\n",
      "Epoch 38/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3391 - val_loss: 0.3422\n",
      "Epoch 39/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3389 - val_loss: 0.3421\n",
      "Epoch 40/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3388 - val_loss: 0.3422\n"
     ]
    }
   ],
   "source": [
    "def run_model(hidden1, hidden2):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(TimeDistributed(Dense(hidden1, activation='sigmoid'), input_shape=movie.shape[1:]))\n",
    "    model.add(TimeDistributed(Dense(hidden2, activation='sigmoid')))\n",
    "    model.add(TimeDistributed(Dense(frhist.shape[2], activation='softplus')))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-7), loss='poisson')\n",
    "    history = model.fit(movie, frhist, epochs=40, batch_size=32, validation_split=0.2, shuffle=True)\n",
    "\n",
    "# for hidden in [30, 40, 50, 60, 75, 100, 150]:\n",
    "#     run_model(hidden, hidden)\n",
    "\n",
    "for hidden in [65, 75, 85, 95]:\n",
    "    run_model(hidden, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_16 (TimeDis (None, 150, 75)           921675    \n",
      "_________________________________________________________________\n",
      "time_distributed_17 (TimeDis (None, 150, 75)           5700      \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 150, 54)           4104      \n",
      "=================================================================\n",
      "Total params: 931,479\n",
      "Trainable params: 931,479\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/40\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.6450 - val_loss: 0.5318\n",
      "Epoch 2/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4914 - val_loss: 0.4347\n",
      "Epoch 3/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4120 - val_loss: 0.3830\n",
      "Epoch 4/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3718 - val_loss: 0.3604\n",
      "Epoch 5/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3551 - val_loss: 0.3510\n",
      "Epoch 6/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3484 - val_loss: 0.3471\n",
      "Epoch 7/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3454 - val_loss: 0.3455\n",
      "Epoch 8/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3439 - val_loss: 0.3445\n",
      "Epoch 9/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3429 - val_loss: 0.3441\n",
      "Epoch 10/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3422 - val_loss: 0.3438\n",
      "Epoch 11/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3417 - val_loss: 0.3433\n",
      "Epoch 12/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3414 - val_loss: 0.3433\n",
      "Epoch 13/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3409 - val_loss: 0.3430\n",
      "Epoch 14/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3406 - val_loss: 0.3430\n",
      "Epoch 15/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3402 - val_loss: 0.3430\n",
      "Epoch 16/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3401 - val_loss: 0.3431\n",
      "Epoch 17/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3397 - val_loss: 0.3433\n",
      "Epoch 18/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3394 - val_loss: 0.3431\n",
      "Epoch 19/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3389 - val_loss: 0.3431\n",
      "Epoch 20/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3386 - val_loss: 0.3431\n",
      "Epoch 21/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3383 - val_loss: 0.3432\n",
      "Epoch 22/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3381 - val_loss: 0.3431\n",
      "Epoch 23/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3377 - val_loss: 0.3432\n",
      "Epoch 24/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3373 - val_loss: 0.3432\n",
      "Epoch 25/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3369 - val_loss: 0.3434\n",
      "Epoch 26/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3367 - val_loss: 0.3431\n",
      "Epoch 27/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3364 - val_loss: 0.3433\n",
      "Epoch 28/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3360 - val_loss: 0.3435\n",
      "Epoch 29/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3356 - val_loss: 0.3433\n",
      "Epoch 30/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3353 - val_loss: 0.3437\n",
      "Epoch 31/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3350 - val_loss: 0.3437\n",
      "Epoch 32/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3347 - val_loss: 0.3438\n",
      "Epoch 33/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3343 - val_loss: 0.3440\n",
      "Epoch 34/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3341 - val_loss: 0.3441\n",
      "Epoch 35/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3338 - val_loss: 0.3447\n",
      "Epoch 36/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3336 - val_loss: 0.3442\n",
      "Epoch 37/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3335 - val_loss: 0.3447\n",
      "Epoch 38/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3333 - val_loss: 0.3445\n",
      "Epoch 39/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3330 - val_loss: 0.3451\n",
      "Epoch 40/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3327 - val_loss: 0.3451\n"
     ]
    }
   ],
   "source": [
    "# why does this overfit more than the sigmoid version?\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(TimeDistributed(Dense(75, activation='tanh'), input_shape=movie.shape[1:]))\n",
    "model.add(TimeDistributed(Dense(75, activation='tanh')))\n",
    "model.add(TimeDistributed(Dense(frhist.shape[2], activation='softplus')))\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-7), loss='poisson')\n",
    "history = model.fit(movie, frhist, epochs=40, batch_size=32, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm_3 (CuDNNLSTM)     (None, 150, 90)           4456800   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 150, 75)           6825      \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 150, 54)           4104      \n",
      "=================================================================\n",
      "Total params: 4,467,729\n",
      "Trainable params: 4,467,729\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/200\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.6921 - val_loss: 0.6045\n",
      "Epoch 2/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.5633 - val_loss: 0.5062\n",
      "Epoch 3/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.4770 - val_loss: 0.4369\n",
      "Epoch 4/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.4193 - val_loss: 0.3948\n",
      "Epoch 5/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3856 - val_loss: 0.3720\n",
      "Epoch 6/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3675 - val_loss: 0.3599\n",
      "Epoch 7/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3575 - val_loss: 0.3534\n",
      "Epoch 8/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3520 - val_loss: 0.3498\n",
      "Epoch 9/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3486 - val_loss: 0.3474\n",
      "Epoch 10/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3466 - val_loss: 0.3459\n",
      "Epoch 11/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3452 - val_loss: 0.3450\n",
      "Epoch 12/200\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.3442 - val_loss: 0.3445\n",
      "Epoch 13/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3436 - val_loss: 0.3440\n",
      "Epoch 14/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3430 - val_loss: 0.3436\n",
      "Epoch 15/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3427 - val_loss: 0.3433\n",
      "Epoch 16/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3422 - val_loss: 0.3432\n",
      "Epoch 17/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3419 - val_loss: 0.3430\n",
      "Epoch 18/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3416 - val_loss: 0.3429\n",
      "Epoch 19/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3414 - val_loss: 0.3428\n",
      "Epoch 20/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3411 - val_loss: 0.3427\n",
      "Epoch 21/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3409 - val_loss: 0.3426\n",
      "Epoch 22/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3407 - val_loss: 0.3425\n",
      "Epoch 23/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3404 - val_loss: 0.3425\n",
      "Epoch 24/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3402 - val_loss: 0.3424\n",
      "Epoch 25/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3400 - val_loss: 0.3423\n",
      "Epoch 26/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3398 - val_loss: 0.3422\n",
      "Epoch 27/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3396 - val_loss: 0.3422\n",
      "Epoch 28/200\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.3393 - val_loss: 0.3422\n",
      "Epoch 29/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3390 - val_loss: 0.3422\n",
      "Epoch 30/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3387 - val_loss: 0.3422\n",
      "Epoch 31/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3384 - val_loss: 0.3421\n",
      "Epoch 32/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3382 - val_loss: 0.3421\n",
      "Epoch 33/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3379 - val_loss: 0.3420\n",
      "Epoch 34/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3375 - val_loss: 0.3420\n",
      "Epoch 35/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3372 - val_loss: 0.3419\n",
      "Epoch 36/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3369 - val_loss: 0.3422\n",
      "Epoch 37/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3367 - val_loss: 0.3422\n",
      "Epoch 38/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3365 - val_loss: 0.3420\n",
      "Epoch 39/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3364 - val_loss: 0.3420\n",
      "Epoch 40/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3361 - val_loss: 0.3422\n",
      "Epoch 41/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3359 - val_loss: 0.3423\n",
      "Epoch 42/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3356 - val_loss: 0.3427\n",
      "Epoch 43/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3354 - val_loss: 0.3427\n",
      "Epoch 44/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3353 - val_loss: 0.3427\n",
      "Epoch 45/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3350 - val_loss: 0.3420\n"
     ]
    }
   ],
   "source": [
    "# recurrence doesn't improve accuracy!\n",
    "from keras.layers import CuDNNLSTM, Dense\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Reshape\n",
    "# from keras.layers import TimeDistributed\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(CuDNNLSTM(90, return_sequences=True, input_shape=movie.shape[1:]))\n",
    "model.add(Dense(75, activation='sigmoid'))\n",
    "model.add(Dense(frhist.shape[2], activation='softplus'))\n",
    "adamopt = keras.optimizers.Adam(lr=0.001, decay=1e-7)\n",
    "\n",
    "model.compile(optimizer=adamopt, loss='poisson')\n",
    "model.summary()\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(movie, frhist, epochs=200, batch_size=32, validation_split=0.2, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_19 (TimeDis (None, 150, 100)          1228900   \n",
      "_________________________________________________________________\n",
      "time_distributed_20 (TimeDis (None, 150, 60)           6060      \n",
      "_________________________________________________________________\n",
      "time_distributed_21 (TimeDis (None, 150, 54)           3294      \n",
      "=================================================================\n",
      "Total params: 1,238,254\n",
      "Trainable params: 1,238,254\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/40\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.7269 - val_loss: 0.6530\n",
      "Epoch 2/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.6192 - val_loss: 0.5711\n",
      "Epoch 3/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.5451 - val_loss: 0.5085\n",
      "Epoch 4/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4889 - val_loss: 0.4624\n",
      "Epoch 5/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4477 - val_loss: 0.4286\n",
      "Epoch 6/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4177 - val_loss: 0.4040\n",
      "Epoch 7/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3961 - val_loss: 0.3863\n",
      "Epoch 8/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3806 - val_loss: 0.3738\n",
      "Epoch 9/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3699 - val_loss: 0.3651\n",
      "Epoch 10/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3625 - val_loss: 0.3592\n",
      "Epoch 11/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3573 - val_loss: 0.3550\n",
      "Epoch 12/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3537 - val_loss: 0.3521\n",
      "Epoch 13/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3510 - val_loss: 0.3500\n",
      "Epoch 14/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3491 - val_loss: 0.3484\n",
      "Epoch 15/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3477 - val_loss: 0.3472\n",
      "Epoch 16/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3466 - val_loss: 0.3463\n",
      "Epoch 17/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3458 - val_loss: 0.3456\n",
      "Epoch 18/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3451 - val_loss: 0.3451\n",
      "Epoch 19/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3446 - val_loss: 0.3447\n",
      "Epoch 20/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3441 - val_loss: 0.3444\n",
      "Epoch 21/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3438 - val_loss: 0.3441\n",
      "Epoch 22/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3435 - val_loss: 0.3438\n",
      "Epoch 23/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3433 - val_loss: 0.3435\n",
      "Epoch 24/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3431 - val_loss: 0.3434\n",
      "Epoch 25/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3428 - val_loss: 0.3433\n",
      "Epoch 26/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3426 - val_loss: 0.3432\n",
      "Epoch 27/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3424 - val_loss: 0.3430\n",
      "Epoch 28/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3423 - val_loss: 0.3429\n",
      "Epoch 29/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3422 - val_loss: 0.3429\n",
      "Epoch 30/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3420 - val_loss: 0.3428\n",
      "Epoch 31/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3419 - val_loss: 0.3427\n",
      "Epoch 32/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3418 - val_loss: 0.3426\n",
      "Epoch 33/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3417 - val_loss: 0.3426\n",
      "Epoch 34/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3416 - val_loss: 0.3426\n",
      "Epoch 35/40\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3414 - val_loss: 0.3425\n",
      "Epoch 36/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3413 - val_loss: 0.3425\n",
      "Epoch 37/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3412 - val_loss: 0.3424\n",
      "Epoch 38/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3411 - val_loss: 0.3423\n",
      "Epoch 39/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3410 - val_loss: 0.3423\n",
      "Epoch 40/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3408 - val_loss: 0.3423\n"
     ]
    }
   ],
   "source": [
    "# bottom-heavy\n",
    "model = keras.models.Sequential()\n",
    "model.add(TimeDistributed(Dense(100, activation='sigmoid'), input_shape=movie.shape[1:]))\n",
    "model.add(TimeDistributed(Dense(60, activation='sigmoid')))\n",
    "model.add(TimeDistributed(Dense(frhist.shape[2], activation='softplus')))\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-7), loss='poisson')\n",
    "history = model.fit(movie, frhist, epochs=40, batch_size=32, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_22 (TimeDis (None, 150, 60)           737340    \n",
      "_________________________________________________________________\n",
      "time_distributed_23 (TimeDis (None, 150, 100)          6100      \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 150, 54)           5454      \n",
      "=================================================================\n",
      "Total params: 748,894\n",
      "Trainable params: 748,894\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/40\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.7221 - val_loss: 0.6271\n",
      "Epoch 2/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.5798 - val_loss: 0.5176\n",
      "Epoch 3/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.4847 - val_loss: 0.4437\n",
      "Epoch 4/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.4228 - val_loss: 0.3977\n",
      "Epoch 5/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3857 - val_loss: 0.3717\n",
      "Epoch 6/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3661 - val_loss: 0.3588\n",
      "Epoch 7/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3559 - val_loss: 0.3523\n",
      "Epoch 8/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3506 - val_loss: 0.3490\n",
      "Epoch 9/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3479 - val_loss: 0.3471\n",
      "Epoch 10/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3460 - val_loss: 0.3457\n",
      "Epoch 11/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3448 - val_loss: 0.3449\n",
      "Epoch 12/40\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3440 - val_loss: 0.3443\n",
      "Epoch 13/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3434 - val_loss: 0.3441\n",
      "Epoch 14/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3431 - val_loss: 0.3437\n",
      "Epoch 15/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3427 - val_loss: 0.3434\n",
      "Epoch 16/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3424 - val_loss: 0.3433\n",
      "Epoch 17/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3421 - val_loss: 0.3432\n",
      "Epoch 18/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3419 - val_loss: 0.3430\n",
      "Epoch 19/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3416 - val_loss: 0.3429\n",
      "Epoch 20/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3414 - val_loss: 0.3429\n",
      "Epoch 21/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3413 - val_loss: 0.3429\n",
      "Epoch 22/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3411 - val_loss: 0.3428\n",
      "Epoch 23/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3409 - val_loss: 0.3428\n",
      "Epoch 24/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3407 - val_loss: 0.3426\n",
      "Epoch 25/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3404 - val_loss: 0.3426\n",
      "Epoch 26/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3402 - val_loss: 0.3426\n",
      "Epoch 27/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3401 - val_loss: 0.3426\n",
      "Epoch 28/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3399 - val_loss: 0.3426\n",
      "Epoch 29/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3398 - val_loss: 0.3426\n",
      "Epoch 30/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3394 - val_loss: 0.3425\n",
      "Epoch 31/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3393 - val_loss: 0.3427\n",
      "Epoch 32/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3390 - val_loss: 0.3425\n",
      "Epoch 33/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3388 - val_loss: 0.3425\n",
      "Epoch 34/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3386 - val_loss: 0.3428\n",
      "Epoch 35/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3384 - val_loss: 0.3428\n",
      "Epoch 36/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3383 - val_loss: 0.3426\n",
      "Epoch 37/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3380 - val_loss: 0.3427\n",
      "Epoch 38/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3378 - val_loss: 0.3426\n",
      "Epoch 39/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3376 - val_loss: 0.3429\n",
      "Epoch 40/40\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3373 - val_loss: 0.3428\n"
     ]
    }
   ],
   "source": [
    "# top-heavy -- converged faster but didn't reach as high of accuracy\n",
    "model = keras.models.Sequential()\n",
    "model.add(TimeDistributed(Dense(60, activation='sigmoid'), input_shape=movie.shape[1:]))\n",
    "model.add(TimeDistributed(Dense(100, activation='sigmoid')))\n",
    "model.add(TimeDistributed(Dense(frhist.shape[2], activation='softplus')))\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-7), loss='poisson')\n",
    "history = model.fit(movie, frhist, epochs=40, batch_size=32, validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like a dense network with two 75-neuron hidden layers is the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_39 (TimeDis (None, 150, 50)           614450    \n",
      "_________________________________________________________________\n",
      "time_distributed_40 (TimeDis (None, 150, 65)           3315      \n",
      "_________________________________________________________________\n",
      "time_distributed_41 (TimeDis (None, 150, 54)           3564      \n",
      "=================================================================\n",
      "Total params: 621,329\n",
      "Trainable params: 621,329\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/200\n",
      "230/230 [==============================] - 4s 18ms/step - loss: 0.7099 - val_loss: 0.6433\n",
      "Epoch 2/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.6095 - val_loss: 0.5620\n",
      "Epoch 3/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.5354 - val_loss: 0.4982\n",
      "Epoch 4/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4784 - val_loss: 0.4506\n",
      "Epoch 5/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4361 - val_loss: 0.4161\n",
      "Epoch 6/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4061 - val_loss: 0.3922\n",
      "Epoch 7/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3854 - val_loss: 0.3759\n",
      "Epoch 8/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3714 - val_loss: 0.3651\n",
      "Epoch 9/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3622 - val_loss: 0.3582\n",
      "Epoch 10/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3563 - val_loss: 0.3538\n",
      "Epoch 11/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3525 - val_loss: 0.3510\n",
      "Epoch 12/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3499 - val_loss: 0.3489\n",
      "Epoch 13/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3481 - val_loss: 0.3474\n",
      "Epoch 14/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3468 - val_loss: 0.3463\n",
      "Epoch 15/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3458 - val_loss: 0.3458\n",
      "Epoch 16/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3451 - val_loss: 0.3451\n",
      "Epoch 17/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3446 - val_loss: 0.3445\n",
      "Epoch 18/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3441 - val_loss: 0.3442\n",
      "Epoch 19/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3438 - val_loss: 0.3440\n",
      "Epoch 20/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3435 - val_loss: 0.3439\n",
      "Epoch 21/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3433 - val_loss: 0.3436\n",
      "Epoch 22/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3431 - val_loss: 0.3434\n",
      "Epoch 23/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3429 - val_loss: 0.3434\n",
      "Epoch 24/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3427 - val_loss: 0.3433\n",
      "Epoch 25/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3426 - val_loss: 0.3430\n",
      "Epoch 26/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3424 - val_loss: 0.3429\n",
      "Epoch 27/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3423 - val_loss: 0.3430\n",
      "Epoch 28/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3422 - val_loss: 0.3427\n",
      "Epoch 29/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3421 - val_loss: 0.3426\n",
      "Epoch 30/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3419 - val_loss: 0.3427\n",
      "Epoch 31/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3417 - val_loss: 0.3427\n",
      "Epoch 32/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3417 - val_loss: 0.3426\n",
      "Epoch 33/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3415 - val_loss: 0.3426\n",
      "Epoch 34/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3414 - val_loss: 0.3426\n",
      "Epoch 35/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3413 - val_loss: 0.3424\n",
      "Epoch 36/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3412 - val_loss: 0.3424\n",
      "Epoch 37/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3411 - val_loss: 0.3424\n",
      "Epoch 38/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3409 - val_loss: 0.3425\n",
      "Epoch 39/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3408 - val_loss: 0.3424\n",
      "Epoch 40/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.3406 - val_loss: 0.3422\n",
      "Epoch 41/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3406 - val_loss: 0.3421\n",
      "Epoch 42/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3404 - val_loss: 0.3422\n",
      "Epoch 43/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3402 - val_loss: 0.3422\n",
      "Epoch 44/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3401 - val_loss: 0.3421\n",
      "Epoch 45/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3399 - val_loss: 0.3420\n",
      "Epoch 46/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3398 - val_loss: 0.3421\n",
      "Epoch 47/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3397 - val_loss: 0.3420\n",
      "Epoch 48/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3396 - val_loss: 0.3421\n",
      "Epoch 49/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3394 - val_loss: 0.3420\n",
      "Epoch 50/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3393 - val_loss: 0.3421\n",
      "Epoch 51/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3391 - val_loss: 0.3420\n",
      "Epoch 52/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3389 - val_loss: 0.3419\n",
      "Epoch 53/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3388 - val_loss: 0.3419\n",
      "Epoch 54/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3386 - val_loss: 0.3421\n",
      "Epoch 55/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3384 - val_loss: 0.3421\n",
      "Epoch 56/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3383 - val_loss: 0.3421\n",
      "Epoch 57/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3383 - val_loss: 0.3420\n",
      "Epoch 58/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3380 - val_loss: 0.3422\n",
      "Epoch 59/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3378 - val_loss: 0.3422\n",
      "Epoch 60/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3377 - val_loss: 0.3422\n",
      "Epoch 61/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3374 - val_loss: 0.3422\n",
      "Epoch 62/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3373 - val_loss: 0.3424\n",
      "Epoch 63/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3371 - val_loss: 0.3422\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(TimeDistributed(Dense(50, activation='sigmoid'), input_shape=movie.shape[1:]))\n",
    "model.add(TimeDistributed(Dense(65, activation='sigmoid')))\n",
    "model.add(TimeDistributed(Dense(frhist.shape[2], activation='softplus')))\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-7), loss='poisson')\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(movie, frhist, epochs=200, batch_size=32, validation_split=0.2, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_1 (TimeDist (None, 150, 50)           614450    \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 150, 54)           2754      \n",
      "=================================================================\n",
      "Total params: 617,204\n",
      "Trainable params: 617,204\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/200\n",
      "230/230 [==============================] - 4s 19ms/step - loss: 0.6763 - val_loss: 0.6240\n",
      "Epoch 2/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.6100 - val_loss: 0.5918\n",
      "Epoch 3/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.5780 - val_loss: 0.5621\n",
      "Epoch 4/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.5491 - val_loss: 0.5350\n",
      "Epoch 5/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.5224 - val_loss: 0.5100\n",
      "Epoch 6/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4987 - val_loss: 0.4877\n",
      "Epoch 7/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4761 - val_loss: 0.4644\n",
      "Epoch 8/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4541 - val_loss: 0.4450\n",
      "Epoch 9/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4363 - val_loss: 0.4295\n",
      "Epoch 10/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4220 - val_loss: 0.4166\n",
      "Epoch 11/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4099 - val_loss: 0.4054\n",
      "Epoch 12/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3992 - val_loss: 0.3952\n",
      "Epoch 13/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3897 - val_loss: 0.3853\n",
      "Epoch 14/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3818 - val_loss: 0.3790\n",
      "Epoch 15/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3756 - val_loss: 0.3737\n",
      "Epoch 16/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3708 - val_loss: 0.3691\n",
      "Epoch 17/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3666 - val_loss: 0.3651\n",
      "Epoch 18/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3634 - val_loss: 0.3624\n",
      "Epoch 19/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3606 - val_loss: 0.3602\n",
      "Epoch 20/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3584 - val_loss: 0.3583\n",
      "Epoch 21/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3565 - val_loss: 0.3566\n",
      "Epoch 22/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3549 - val_loss: 0.3551\n",
      "Epoch 23/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3535 - val_loss: 0.3540\n",
      "Epoch 24/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3520 - val_loss: 0.3529\n",
      "Epoch 25/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3508 - val_loss: 0.3518\n",
      "Epoch 26/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3498 - val_loss: 0.3510\n",
      "Epoch 27/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3489 - val_loss: 0.3503\n",
      "Epoch 28/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3481 - val_loss: 0.3495\n",
      "Epoch 29/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3474 - val_loss: 0.3490\n",
      "Epoch 30/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3468 - val_loss: 0.3483\n",
      "Epoch 31/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3461 - val_loss: 0.3477\n",
      "Epoch 32/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3458 - val_loss: 0.3476\n",
      "Epoch 33/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3452 - val_loss: 0.3472\n",
      "Epoch 34/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3447 - val_loss: 0.3467\n",
      "Epoch 35/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3441 - val_loss: 0.3465\n",
      "Epoch 36/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3439 - val_loss: 0.3459\n",
      "Epoch 37/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3434 - val_loss: 0.3457\n",
      "Epoch 38/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3429 - val_loss: 0.3454\n",
      "Epoch 39/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3426 - val_loss: 0.3452\n",
      "Epoch 40/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3423 - val_loss: 0.3451\n",
      "Epoch 41/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3419 - val_loss: 0.3449\n",
      "Epoch 42/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3417 - val_loss: 0.3447\n",
      "Epoch 43/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3414 - val_loss: 0.3446\n",
      "Epoch 44/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3412 - val_loss: 0.3445\n",
      "Epoch 45/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3409 - val_loss: 0.3443\n",
      "Epoch 46/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3407 - val_loss: 0.3440\n",
      "Epoch 47/200\n",
      "230/230 [==============================] - 3s 13ms/step - loss: 0.3405 - val_loss: 0.3438\n",
      "Epoch 48/200\n",
      "230/230 [==============================] - 3s 13ms/step - loss: 0.3403 - val_loss: 0.3437\n",
      "Epoch 49/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3401 - val_loss: 0.3438\n",
      "Epoch 50/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3399 - val_loss: 0.3437\n",
      "Epoch 51/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3397 - val_loss: 0.3435\n",
      "Epoch 52/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3396 - val_loss: 0.3436\n",
      "Epoch 53/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3393 - val_loss: 0.3434\n",
      "Epoch 54/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3390 - val_loss: 0.3434\n",
      "Epoch 55/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3388 - val_loss: 0.3436\n",
      "Epoch 56/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3385 - val_loss: 0.3435\n",
      "Epoch 57/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3383 - val_loss: 0.3434\n",
      "Epoch 58/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3384 - val_loss: 0.3436\n",
      "Epoch 59/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3384 - val_loss: 0.3434\n",
      "Epoch 60/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3381 - val_loss: 0.3432\n",
      "Epoch 61/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3377 - val_loss: 0.3430\n",
      "Epoch 62/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3374 - val_loss: 0.3433\n",
      "Epoch 63/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3371 - val_loss: 0.3431\n",
      "Epoch 64/200\n",
      "230/230 [==============================] - 4s 15ms/step - loss: 0.3370 - val_loss: 0.3433\n",
      "Epoch 65/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3369 - val_loss: 0.3432\n",
      "Epoch 66/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3370 - val_loss: 0.3431\n",
      "Epoch 67/200\n",
      "230/230 [==============================] - 3s 14ms/step - loss: 0.3366 - val_loss: 0.3435\n",
      "Epoch 68/200\n",
      "230/230 [==============================] - 3s 15ms/step - loss: 0.3364 - val_loss: 0.3432\n",
      "Epoch 69/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3365 - val_loss: 0.3433\n",
      "Epoch 70/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3364 - val_loss: 0.3433\n",
      "Epoch 71/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3360 - val_loss: 0.3433\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(TimeDistributed(Dense(50, activation='sigmoid'), input_shape=movie.shape[1:]))\n",
    "model.add(TimeDistributed(Dense(frhist.shape[2], activation='softplus')))\n",
    "model.summary()\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-7), loss='poisson')\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = model.fit(movie, frhist, epochs=200, batch_size=32, validation_split=0.2, shuffle=True, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_9 (TimeDist (None, 150, 80)           983120    \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, 150, 54)           4374      \n",
      "=================================================================\n",
      "Total params: 987,494\n",
      "Trainable params: 987,494\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 230 samples, validate on 58 samples\n",
      "Epoch 1/200\n",
      "230/230 [==============================] - 4s 17ms/step - loss: 0.6330 - val_loss: 0.5450\n",
      "Epoch 2/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.5177 - val_loss: 0.4816\n",
      "Epoch 3/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4611 - val_loss: 0.4366\n",
      "Epoch 4/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.4220 - val_loss: 0.4062\n",
      "Epoch 5/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3958 - val_loss: 0.3863\n",
      "Epoch 6/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3786 - val_loss: 0.3733\n",
      "Epoch 7/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3678 - val_loss: 0.3648\n",
      "Epoch 8/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3606 - val_loss: 0.3594\n",
      "Epoch 9/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3558 - val_loss: 0.3556\n",
      "Epoch 10/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3524 - val_loss: 0.3529\n",
      "Epoch 11/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3499 - val_loss: 0.3510\n",
      "Epoch 12/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3480 - val_loss: 0.3495\n",
      "Epoch 13/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3466 - val_loss: 0.3484\n",
      "Epoch 14/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3454 - val_loss: 0.3475\n",
      "Epoch 15/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3444 - val_loss: 0.3469\n",
      "Epoch 16/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3437 - val_loss: 0.3460\n",
      "Epoch 17/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3430 - val_loss: 0.3456\n",
      "Epoch 18/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3424 - val_loss: 0.3452\n",
      "Epoch 19/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3418 - val_loss: 0.3448\n",
      "Epoch 20/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3413 - val_loss: 0.3443\n",
      "Epoch 21/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3409 - val_loss: 0.3440\n",
      "Epoch 22/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3405 - val_loss: 0.3437\n",
      "Epoch 23/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3401 - val_loss: 0.3436\n",
      "Epoch 24/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3396 - val_loss: 0.3435\n",
      "Epoch 25/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3393 - val_loss: 0.3434\n",
      "Epoch 26/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3391 - val_loss: 0.3432\n",
      "Epoch 27/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3388 - val_loss: 0.3433\n",
      "Epoch 28/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3386 - val_loss: 0.3434\n",
      "Epoch 29/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3385 - val_loss: 0.3432\n",
      "Epoch 30/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3381 - val_loss: 0.3432\n",
      "Epoch 31/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3377 - val_loss: 0.3431\n",
      "Epoch 32/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3378 - val_loss: 0.3430\n",
      "Epoch 33/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3375 - val_loss: 0.3431\n",
      "Epoch 34/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3372 - val_loss: 0.3431\n",
      "Epoch 35/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3370 - val_loss: 0.3431\n",
      "Epoch 36/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3366 - val_loss: 0.3431\n",
      "Epoch 37/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3365 - val_loss: 0.3429\n",
      "Epoch 38/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3362 - val_loss: 0.3430\n",
      "Epoch 39/200\n",
      "230/230 [==============================] - 4s 16ms/step - loss: 0.3360 - val_loss: 0.3428\n",
      "Epoch 40/200\n",
      "160/230 [===================>..........] - ETA: 0s - loss: 0.3343"
     ]
    }
   ],
   "source": [
    "# single hidden-layer models do almost as well\n",
    "def run_model(hidden):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(TimeDistributed(Dense(hidden, activation='sigmoid'), input_shape=movie.shape[1:]))\n",
    "    model.add(TimeDistributed(Dense(frhist.shape[2], activation='softplus')))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=keras.optimizers.Adam(lr=0.001, decay=1e-7), loss='poisson')\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
    "    history = model.fit(movie, frhist, epochs=200, batch_size=32, validation_split=0.2, shuffle=True, callbacks=[early_stopping])\n",
    "    \n",
    "for h in [80, 70, 60]:\n",
    "    run_model(h)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
